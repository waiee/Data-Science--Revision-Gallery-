{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kW_U0PE4gkyt"
   },
   "source": [
    "<img src=\"https://www.mmu.edu.my/fci/wp-content/uploads/2021/01/FCI_wNEW_MMU_LOGO.png\" style=\"height: 80px;\" align=left>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uwBEqOvDgkyv"
   },
   "source": [
    "# Tutorial 1 (Part 1): Concepts and Data Structure\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "Towards the end of this lesson, you should be able to:\n",
    "- understand the concepts in data mining\n",
    "- creating a dataframe using dictionary\n",
    "- using Pandas to manipulate structured dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmZy_fhxgWS7"
   },
   "source": [
    "---\n",
    "\n",
    "## Theoretical Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwkANx46gWS8"
   },
   "source": [
    "### Question 1\n",
    "Describe the steps involved in data mining when viewed as a process of knowledge\n",
    "discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_3S9J_cfaG5"
   },
   "source": [
    "1. Data Cleaning & Data Integration: \n",
    "- Data Cleaning involves removing duplicates/handling missing values and standardizing\n",
    "data formats. Data integration is the process of combining data from different sources.\n",
    "\n",
    "2. Data selection and data transformation:\n",
    "Select releevant data for mining task, transform the data into appropriate \n",
    "format for mining algorithm. \n",
    "\n",
    "3. Choosing mining algorithm: Choose the appropriate data mining algorithm based on the \n",
    "problem and data charateristics.\n",
    "\n",
    "4. Pattern Evaluation and knowledge representation:\n",
    "evaluate truly interesting patterns using interestingness measures, then\n",
    "visualize the patterns, in order to effective present to knowledge to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZdHgTZagWS8"
   },
   "source": [
    "### Question 2\n",
    "What data mining function does a department store need to assist with its target marketing mail campaign? Can they be performed alternatively by data query processing or simple statistical analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6F-SKYIfdUp"
   },
   "source": [
    "ARM: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJq4xY50gWS8"
   },
   "source": [
    "### Question 3\n",
    "What is the difference between characterization and clustering? Between classification and prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BPvCoXe1g8bY"
   },
   "source": [
    "characterization: refers to a summarization of the general\n",
    "characteristics or features of a target class of data.\n",
    "\n",
    "Cluster analysis is one of data mining function.\n",
    "• Class label is unknown: Group data to form new classes,\n",
    "e.g. cluster houses to find distribution patterns\n",
    "• Clustering based on the principle: maximizing the intra-class\n",
    "similarity and minimizing interclass similarity\n",
    "\n",
    "\n",
    "• Classification: predict the class label given new observation.\n",
    "• Prediction: predict some unknown or missing numerical values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fe21ylsMgWS9"
   },
   "source": [
    "### Question 4\n",
    "For each of the following problem scenarios, decide if a solution would best be addressed with supervised learning, unsupervised clustering or database query. If you decide that supervised learning or unsupervised clustering is the best answer, list several input attributes you believe to be relevant for solving the problem.\n",
    "\n",
    "a) When customers visit my Web site, what products are they most likely to buy?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mvgaug9ei2GA"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8i-k5Wzaip1A"
   },
   "source": [
    "b)\tWhat percent of my employees miss one or more days of work per month?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMtDbj0xkMQI"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0bBJPI0iyqI"
   },
   "source": [
    "c) What relationships can I find between an individual's height, weight, age and favorite spectator sport?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QJ8W1MCkbnP"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSTE-EJmXYOs"
   },
   "source": [
    "---\n",
    "\n",
    "## Practical Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9pUsG_UQgkyv"
   },
   "outputs": [],
   "source": [
    "#!conda install pandas\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RNqOK-ccT6i"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "### For Google Colab Use Only\n",
    "Skip this section if you are using Jupyter Notebook etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DE6XffsuclLs"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jcx6xDmdco5S"
   },
   "outputs": [],
   "source": [
    "path = '/content/drive/MyDrive/' #set your google drive path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yh2nczDegkyw"
   },
   "source": [
    "---\n",
    "\n",
    "## Series\n",
    "Series form the basis of Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOPo3e2xgkyw"
   },
   "source": [
    "### Initializing Series\n",
    "Series can be initialized from Python objects like lists or tuples. If only values are given, Pandas generates default indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UrRcPgshgkyw"
   },
   "outputs": [],
   "source": [
    "fruits = ['apple', 'banana', 'durian']\n",
    "pd.Series(fruits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vi5I9mfKgkyx"
   },
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3]\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STgYr7wvgkyy"
   },
   "source": [
    "Series can be mixed type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zm_HuWkzgkyy"
   },
   "outputs": [],
   "source": [
    "# Create a mixed series\n",
    "import pandas as pd\n",
    "mixed = [1, 2, \"Three\"]\n",
    "print(pd.Series(mixed))\n",
    "print()\n",
    "print(type(mixed[0]))\n",
    "print(type(mixed[1]))\n",
    "print(type(mixed[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8d6h4nSgkyy"
   },
   "source": [
    "Series also support missing values via the `None` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LPxZrF9_gkyy"
   },
   "outputs": [],
   "source": [
    "#create a pandas series with None\n",
    "#observe the dtype\n",
    "\n",
    "fruits = ['apple', 'banana', 'durian']\n",
    "print(pd.Series(fruits))\n",
    "print(\"\")\n",
    "print(type(fruits[0]))\n",
    "print(type(fruits[1]))\n",
    "print(type(fruits[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vxRELJUsgkyz"
   },
   "outputs": [],
   "source": [
    "# using the None keyword in list --> NaN in series\n",
    "\n",
    "import numpy as np\n",
    "numbers = [1, 2, None]\n",
    "print(pd.Series(numbers))\n",
    "print(\"\")\n",
    "print(type(numbers[0]))\n",
    "print(type(numbers[1]))\n",
    "print(type(numbers[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGsWT3s9gkyz"
   },
   "source": [
    "We can define custom keys during initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHcP4Zo1gkyz"
   },
   "outputs": [],
   "source": [
    "# need to be careful with index. Index can be numbers.\n",
    "\n",
    "fruits = pd.Series(\n",
    "    data=[\"apple\", \"banana\", \"pineapple\", \"durian\"])\n",
    "print(fruits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-V9x2Rqgkyz"
   },
   "outputs": [],
   "source": [
    "# need to be careful with index. Index can be characters.\n",
    "\n",
    "fruits = pd.Series(\n",
    "    data=[\"apple\", \"banana\", \"pineapple\", \"durian\"],\n",
    "    index=[\"a\", \"b\", \"c\", \"d\"])\n",
    "print(fruits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcdkv689gkyz"
   },
   "source": [
    "Alternatively, Series can also be initialized with dictionaries. Indices are then generated from the dictionary keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ei2U0B4Ogky0"
   },
   "outputs": [],
   "source": [
    "# define our own dictionary\n",
    "\n",
    "dict = {\n",
    "    'australia': 'apple',\n",
    "    'malaysia': 'durian',\n",
    "    'thailand': 'coconut',\n",
    "    'philipines': 'mango'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1tKWxCugky0"
   },
   "outputs": [],
   "source": [
    "#create a pandas series from dictionary\n",
    "\n",
    "country = pd.Series(dict)\n",
    "print(country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIrnfZNfgky0"
   },
   "source": [
    "We can list values and indices of series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1up8aPSgky0"
   },
   "outputs": [],
   "source": [
    "print(country.index)\n",
    "print(country.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfGGY8-Vgky0"
   },
   "source": [
    "Series type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aVw_fdQ-gky0"
   },
   "outputs": [],
   "source": [
    "type(country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9Ck3qsWgky1"
   },
   "source": [
    "### Selecting Elements - IMPORTANT\n",
    "As a result of iterative development of the Pandas library, there are several ways to select elements of a Series. Most of them are considered \"legacy\", however, and the best practice is to use `*.loc[...]` and `*.iloc[...]`. Take care to use the square brackets with `loc` and `iloc`, *not* the regular brackets as you would with functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7Vrxp2Ogky1"
   },
   "source": [
    "#### loc\n",
    "Select elements by their indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UOMgSeyPgky1"
   },
   "outputs": [],
   "source": [
    "country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUujQzvlgky1"
   },
   "outputs": [],
   "source": [
    "print(country.loc['malaysia'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqbQKCpJgky1"
   },
   "source": [
    "#### iloc\n",
    "Select elements by their numerical IDs, i.e. the n-th element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4mP891agky1"
   },
   "outputs": [],
   "source": [
    "print(country.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IBtK6Mzgky1"
   },
   "source": [
    "If the indices were autogenerated then both loc and iloc seem to be identical. This is **NOT** always the case !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fCG0ti3Cgky2"
   },
   "outputs": [],
   "source": [
    "country_noindex = pd.Series(country.values)\n",
    "print(country_noindex)\n",
    "print(\"\")\n",
    "print(country_noindex.loc[0])\n",
    "print(country_noindex.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OuqhsCF1gky2"
   },
   "source": [
    "Now, change the position by using **sort_values()** command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QcrS2ebrgky2"
   },
   "outputs": [],
   "source": [
    "# make sure you check the index sequence\n",
    "\n",
    "country_noindex_sorted = country_noindex.sort_values()\n",
    "print(country_noindex_sorted)\n",
    "print(\"\")\n",
    "print(country_noindex_sorted.loc[1])\n",
    "print(country_noindex_sorted.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNbPWIuYgky2"
   },
   "source": [
    "If you want to select by index then use `loc`, if you want to select by ID then use `iloc`. Do not use them interchangeably just because they return the same results right now. This will eventually lead to bugs in your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inhjOYVPgky2"
   },
   "source": [
    "### Combining Series\n",
    "Series can be combined by appending one to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xZryhXmLgky2"
   },
   "outputs": [],
   "source": [
    "# using the append command\n",
    "\n",
    "s1 = pd.Series([\"A\", \"B\", \"C\"])\n",
    "s2 = pd.Series([\"D\", \"E\", \"F\"])\n",
    "print(s1)\n",
    "print(\"\")\n",
    "print(s2)\n",
    "print(\"\")\n",
    "\n",
    "s3 = s1.append(s2)\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRvPKMEpgky2"
   },
   "source": [
    "Notice the duplicate indices! Pandas permits this and selecting by `loc` will return **both** entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ehD6ikvgky3"
   },
   "outputs": [],
   "source": [
    "print(s3.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GadN2WQ1gky3"
   },
   "source": [
    "Using ``iloc`` will only return based on index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AxteqySrgky3"
   },
   "outputs": [],
   "source": [
    "print(s3.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOIMpxHjgky3"
   },
   "source": [
    "Also notice that if your selection of a Series results in a single entry, Pandas automatically converts it to its base type, i.e. a string in this case. If the selection consists of more than 1 entry, however, a Series is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6KbSvsbgky4"
   },
   "outputs": [],
   "source": [
    "print(s3.loc[0])\n",
    "print(type(s3.loc[0]))\n",
    "print(\"\")\n",
    "print(s3.iloc[0])\n",
    "print(type(s3.iloc[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrwVbcEzgky4"
   },
   "source": [
    "## DataFrames\n",
    "\n",
    "Multiple series with common indices can form a data frame. A data frame is like a table, with rows and columns (e.g., as in SQL or Excel).\n",
    "\n",
    "|     | Region | Weather |\n",
    "| --- | --- | --- |\n",
    "| India | asia | warm |\n",
    "| Sweden | europe | cold |\n",
    "\n",
    "Each row usually denotes an entry in our data and each column a feature we're interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "htC04KJegky4"
   },
   "source": [
    "### Creating DataFrames from Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ns50DTxZgky4"
   },
   "outputs": [],
   "source": [
    "dict = {\n",
    "    'Region':['asia','europe'],\n",
    "    'Weather':['warm', 'cold']\n",
    "    }\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BxjzFKhagky4"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxyXBSWIgky4"
   },
   "source": [
    "We can use the same `*.index()` and `*.values()` functions as for Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VVetlI9egky5"
   },
   "outputs": [],
   "source": [
    "print(df.index)\n",
    "print(df.columns)\n",
    "print(df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmIH0GZGgky5"
   },
   "source": [
    "### Pandas Pretty Print in Jupyter\n",
    "\n",
    "A better way to display the output of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4drm28bgky5"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pZOxmK0gky5"
   },
   "source": [
    "Jupyter allows a shortcut for the `display` function. If we execute a Python command or line of code that results in a data frame, Jupyter will assume we want to display it and do so using its built-in function. Note, however, that it will only ever do this with the last relevant line in each cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FqnY2tjqgky5"
   },
   "source": [
    "### Importing and Exporting Data\n",
    "Most often we don't create data within our code but read it from external sources. Pandas has a large collection of importing (and corresponding exporting) functions available.\n",
    "\n",
    "| Data | Reader | Writer |\n",
    "| --- | --- | --- |\n",
    "| CSV | `read_csv` | `to_csv` |\n",
    "| JSON | `read_json` | `to_json` |\n",
    "| HTML | `read_html` | `to_html` |\n",
    "| Local clipboard | `read_clipboard` | `to_clipboard` |\n",
    "| Excel | `read_excel` | `to_excel` |\n",
    "| HDF5 | `read_hdf` | `to_hdf` |\n",
    "| Feather | `read_feather` | `to_feather` |\n",
    "| Parquet | `read_parquet` | `to_parquet` |\n",
    "| Msgpack | `read_msgpack` | `to_msgpack` |\n",
    "| Stata | `read_stata` | `to_stata` |\n",
    "| SAS | `read_sas` |  |\n",
    "| Python Picke Format | `read_pickle` | `to_pickle` |\n",
    "| SQL | `read_sql` | `to_sql` |\n",
    "| Google Big Query | `read_gbq` | `to_gbq` |\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/io.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdDbbF7bgky5"
   },
   "source": [
    "#### Reading CSV\n",
    "We will read a tabular CSV file as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYcBapBVgky5"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    path\n",
    "except NameError:\n",
    "    path = ''\n",
    "\n",
    "df = pd.read_csv(path + \"banking.csv\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2vJTNDBgky6"
   },
   "source": [
    "Check the **Shape** of the dataframe. It is represented as (*row*,*column*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KUzBJmIAgky6"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzSaGkr9gky6"
   },
   "source": [
    "Get all the columns of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VZg_uINWgky6"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DZkLUshgky7"
   },
   "source": [
    "#### Writing CSV\n",
    "Writing CSV files is as straightforward as it gets. Notice that these functions are now methods of the specific objects, not of base Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DRi3mnKKgky7"
   },
   "outputs": [],
   "source": [
    "df.to_csv(path + \"telemarket2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r1E54h95gky7"
   },
   "source": [
    "### Selecting Data\n",
    "Selecting data from Pandas arrays works just as it did for NumPy arrays, except that `loc` and `iloc` are necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EbUc436cgky7"
   },
   "outputs": [],
   "source": [
    "# row with index no. 9\n",
    "\n",
    "df.iloc[[9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GqFj5Sutgky7"
   },
   "outputs": [],
   "source": [
    "# row with index 4 to 6\n",
    "\n",
    "df.iloc[4:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9duOkqNdgky8"
   },
   "outputs": [],
   "source": [
    "# skip 2\n",
    "\n",
    "df.iloc[1:9:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8CaKFnj7gky8"
   },
   "source": [
    "Selecting columns from a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rha5Somggky8"
   },
   "outputs": [],
   "source": [
    "# select column = 'disp' only\n",
    "\n",
    "df[[\"age\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o2Yc412mgky8"
   },
   "outputs": [],
   "source": [
    "# select 2 columns.\n",
    "\n",
    "df[[\"age\", \"job\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4s73yKhgky8"
   },
   "source": [
    "Alternatively, we can also use the `*.loc`/`.*iloc` syntax. In this case, we have to include both the row and column indices to select. As with base Python, the color `:` instructs Pandas to select all rows or columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fF_de_-Sgky9"
   },
   "outputs": [],
   "source": [
    "# select column = 'disp'\n",
    "\n",
    "df.loc[:, [\"job\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzGln1Q7gky9"
   },
   "source": [
    "Extracting data for a particular row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OL1lpesegky9"
   },
   "outputs": [],
   "source": [
    "display(df.iloc[[4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYlIFoM3gky9"
   },
   "source": [
    "Extracting data for a particular cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ddC1FHZgky9"
   },
   "outputs": [],
   "source": [
    "df.iloc[4].loc[\"job\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JnCwOajKgky9"
   },
   "source": [
    "Filtering the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bv7FsrsWgky-"
   },
   "outputs": [],
   "source": [
    "# Pandas applies the operation to each individual entry\n",
    "\n",
    "df[\"age\"] > 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qmUYXDkwgky-"
   },
   "outputs": [],
   "source": [
    "# Use loc, not iloc, to select based on boolean masks\n",
    "\n",
    "df.loc[df[\"age\"] > 25].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9q-vCSGgky-"
   },
   "source": [
    "We can also select specific rows of certain columns with boolean masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gl-oNjY8gky-"
   },
   "outputs": [],
   "source": [
    "# select specific columns\n",
    "\n",
    "df.loc[df[\"age\"] > 25, [\"job\",\"housing\",'education']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVKz_Wvjgky-"
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jeiHYkFKgky_"
   },
   "outputs": [],
   "source": [
    "# select specific cell...\n",
    "\n",
    "df.iloc[3, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hs6ZpAzKgky_"
   },
   "source": [
    "## Data Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bpd-fC8bgky_"
   },
   "source": [
    "### Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vg-waIrmgky_"
   },
   "outputs": [],
   "source": [
    "print(df['age'].sum())\n",
    "print(df['age'].mean())\n",
    "print(df['age'].max())\n",
    "print(df['age'].min())\n",
    "print(df['age'].idxmax())\n",
    "print(df['age'].idxmin())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxT6Ltdngky_"
   },
   "source": [
    "Functions can be applied to series or data.frames. In the case of data frames, they are applied to each row or column individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HZwaNCH2gky_"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OrTUFdZ1gkzA"
   },
   "outputs": [],
   "source": [
    "df_1 = df[['age','duration','pdays']]\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zjU6lkoFgkzA"
   },
   "outputs": [],
   "source": [
    "# Mean by column\n",
    "\n",
    "df_1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drvgjZnBgkzA"
   },
   "outputs": [],
   "source": [
    "# check for each column, which index has the max value\n",
    "\n",
    "df_1.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbpTDK6JgkzA"
   },
   "source": [
    "We can decide whether the aggregation should occur along columns or rows. Note however, that the syntax is confusing. `axis=X` indicates along which dimension the function will \"travel\". For example, `axis=columns` indicates that all columns will be collapsed into the function, and the function will be applied to individual rows. Likewise, `axis=rows` means that the function will travel along rows and compute the aggregate value for each column individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "04G6Sg2HgkzA"
   },
   "outputs": [],
   "source": [
    "# sum the value for each column.\n",
    "\n",
    "df_1.sum(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vKuWlVtwgkzA"
   },
   "outputs": [],
   "source": [
    "# sum the value for each row.\n",
    "\n",
    "df_1.sum(axis='rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3-eAEFSgkzB"
   },
   "source": [
    "The most important aggregation function is `*.apply()`, which applies an arbitrary function to each row/column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HMeZwNizgkzB"
   },
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame([[1,1,1],[2,2,2],[3,3,3]])\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y9hWjJT-gkzB"
   },
   "outputs": [],
   "source": [
    "df_2.apply(lambda x: sum(x**2), axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWVyL5CTgkzB"
   },
   "source": [
    "What if you sum up columns that are NOT numerical values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9X2qmIZegkzB"
   },
   "outputs": [],
   "source": [
    "df_3 = pd.DataFrame({\n",
    "    \"Age\": [10, 12, 12],\n",
    "    \"Name\": [\"Liz\", \"John\", \"Sam\"]})\n",
    "display(df_3)\n",
    "df_3.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzid5ezCgkzC"
   },
   "source": [
    "### Arithmetic\n",
    "We can also perform element-wise operations on dataframe columns or rows, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ZHN0zZegkzC"
   },
   "outputs": [],
   "source": [
    "df_4 = pd.DataFrame(\n",
    "    data=[[1,1,1],[2,2,2],[3,3,3]],\n",
    "    columns=[\"ColA\", \"ColB\", \"ColC\"],\n",
    "    index=[\"RowA\", \"RowB\", \"RowC\"])\n",
    "df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l44NKEApgkzC"
   },
   "outputs": [],
   "source": [
    "df_4[\"ColA\"] + df_4[\"ColB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_Cqe6n-gkzC"
   },
   "outputs": [],
   "source": [
    "# Pandas is smart enough to convert our list into a series and then add the two columns element-wise\n",
    "\n",
    "df_4[\"ColA\"] + [10, 11, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wf0MyDB1gkzC"
   },
   "outputs": [],
   "source": [
    "# Remember, both rows AND columns can be represented as Pandas series\n",
    "\n",
    "df_4.loc[\"RowA\"] * df_4.loc[\"RowB\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3OCtw05gkzC"
   },
   "source": [
    "Pandas adheres to the same broadcasting rules as NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JDhluLKXgkzC"
   },
   "outputs": [],
   "source": [
    "df_4[\"New\"] = df_4[\"ColB\"] ** 3\n",
    "df_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ic4BlLvjgkzD"
   },
   "source": [
    "### Grouping\n",
    "A core functionality of Pandas is the ability to group data frames and apply functions to each individual group. The function `*.groupby(...)` defines groups based on common labels. Aggregators applied to this grouped data frame are then applied to each group individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bh7isAXlgkzD"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Height\": [178, 182, 158, 167, 177, 174, 175, 185],\n",
    "    \"Age\": [24, 33, 32, 18, 21, 28, 22, 29],\n",
    "    \"Gender\": [\"M\", \"M\", \"F\", \"F\", \"M\", \"F\", \"M\", \"F\"]})\n",
    "display(df)\n",
    "print(df.groupby(\"Gender\"))\n",
    "display(df.groupby(\"Gender\").mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMehNyVOgkzD"
   },
   "source": [
    "We can also select columns without disturbing the grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7UfWEiSzgkzD"
   },
   "outputs": [],
   "source": [
    "# grouping...\n",
    "\n",
    "print(df.groupby(\"Gender\")[\"Height\"])\n",
    "display(df.groupby(\"Gender\")[[\"Height\"]].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "no4CGLq7gkzD"
   },
   "source": [
    "A useful function is `size()`, which counts how large each of the groups is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7ORa5KDgkzD"
   },
   "outputs": [],
   "source": [
    "# size is actually calculating the number of M and F\n",
    "\n",
    "df.groupby(\"Gender\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfvxAVcPgkzD"
   },
   "source": [
    "### Unique and Duplicated Values\n",
    "Two functions can help us identify unique and duplicated values within Series objects. They are aptly names `unique()` and `duplicated()`, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3hZWqc7gkzE"
   },
   "source": [
    "#### unique\n",
    "`*.unique()` returns only unique values of a **Series** object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-SquUqTgkzE"
   },
   "outputs": [],
   "source": [
    "df['Gender'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIX2yS4rgkzE"
   },
   "source": [
    "#### duplicated\n",
    "`*.duplicated()` identifies duplicated values in Series objects and returns a boolean Series. Entries that have already been seen are marked as `True` while new values are marked as `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BnQ2Pe6igkzE"
   },
   "outputs": [],
   "source": [
    "df['Gender'].duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNR9mtB7gkzE"
   },
   "source": [
    "When applied to Dataframes, `duplicated()` compares **ENTIRE ROWS** for duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6C0wJAjmgkzE"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\n",
    "    [\"Dog\", 5],\n",
    "    [\"Cat\", 4],\n",
    "    [\"Dog\", 5],\n",
    "    [\"Fish\", 2],\n",
    "    [\"Cat\", 8]],\n",
    "    columns=[\"Animal\", \"Age\"])\n",
    "display(df)\n",
    "display(df.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0iDPV7lgkzE"
   },
   "source": [
    "To remove duplicated rows from a data frame we could therefore do the following (just like in NumPy, booleans are negated with `~`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JyLxJgUcgkzF"
   },
   "outputs": [],
   "source": [
    "df[~df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjdSTkOsgkzF"
   },
   "outputs": [],
   "source": [
    "# get the unique values in a column\n",
    "\n",
    "df.Animal.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6yM8-gtgkzF"
   },
   "source": [
    "## Merge Data Frames\n",
    "Pandas data frames can be treated like SQL tables and joined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PcMkFJYIgkzF"
   },
   "outputs": [],
   "source": [
    "sales = pd.DataFrame({\n",
    "    \"Date\": pd.date_range(start=\"2018-10-01\", end=\"2018-10-07\"),\n",
    "    \"ItemID\": [\"A401\", \"C776\", \"A401\", \"FY554\", \"Y98R\", \"Y98R\", \"FY554\"]})\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ezr4ZCCMgkzF"
   },
   "outputs": [],
   "source": [
    "item_info = pd.DataFrame({\n",
    "    \"ID\": [\"A401\", \"C776\", \"FY554\", \"Y98R\"],\n",
    "    \"Name\": [\"Toaster\", \"Vacuum Cleaner\", \"Washing Machine\", \"Clothes Iron\"],\n",
    "    \"Price\": [25, 220, 540, 85]})\n",
    "item_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNpwwDQagkzF"
   },
   "outputs": [],
   "source": [
    "sales.merge(right=item_info, how=\"inner\", left_on=\"ItemID\", right_on=\"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sc6I1Le4gkzF"
   },
   "source": [
    "Merge types:\n",
    "- **Inner**: keep only rows with corresponding IDs found in *both* data frames\n",
    "- **Left**: use only rows with IDs found in the left data frame\n",
    "- **Right**: use only rows with IDs found in the right data frame\n",
    "- **Outer**: use all keys that are in at least one of the data frames. This is essentially the combination of left and right joins\n",
    "\n",
    "Missing data will be replaced by `NaN` values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iScPzh3ogkzF"
   },
   "source": [
    "Merge the three data frames so that we have all information available for Bob, Alice, Kevin, and Joshua in a single data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qoUS2KoygkzG"
   },
   "outputs": [],
   "source": [
    "salaries = pd.DataFrame(\n",
    "    data=[[\"Ting\", 5000], [\"Chong\", 4000], [\"David\", 8000]],\n",
    "    columns=[\"Name\", \"Salary\"])\n",
    "departments = pd.DataFrame(\n",
    "    data=[[\"Ting\", \"IT\"], [\"Evelyn\", \"Data Science\"], [\"Chong\", \"Data Science\"]],\n",
    "    columns=[\"Name\", \"Department\"])\n",
    "supervisors = pd.DataFrame(\n",
    "    data=[[\"IT\", \"Richard\"], [\"Data Science\", \"Darren\"], [\"Sales\", \"Yvonne\"]],\n",
    "    columns=[\"Department\", \"Supervisor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQREU0x5gkzG"
   },
   "outputs": [],
   "source": [
    "display(salaries, departments, supervisors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RT7yAxgggkzG"
   },
   "outputs": [],
   "source": [
    "# MC\n",
    "df1 = salaries.merge(departments, how=\"outer\",\n",
    "                     left_on=\"Name\", right_on=\"Name\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EfRPfqJCgkzG"
   },
   "outputs": [],
   "source": [
    "df2 = df1.merge(supervisors, how=\"left\",\n",
    "               left_on=\"Department\", right_on=\"Department\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbXiffaQgkzG"
   },
   "outputs": [],
   "source": [
    "salaries.merge(departments, how=\"outer\").merge(supervisors, how=\"left\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
