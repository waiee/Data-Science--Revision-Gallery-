{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20SLii5H81QG"
   },
   "source": [
    "<img src=\"https://www.mmu.edu.my/fci/wp-content/uploads/2021/01/FCI_wNEW_MMU_LOGO.png\" style=\"height: 80px;\" align=left>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTbVcO-e81QP"
   },
   "source": [
    "# Learning Objectives\n",
    "\n",
    "Towards the end of this lesson, you should be able to:\n",
    "- perform preliminary investigation on dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RNqOK-ccT6i"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "### For Google Colab Use Only\n",
    "Skip this section if you are using Jupyter Notebook etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DE6XffsuclLs"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jcx6xDmdco5S"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/MyDrive/Trimester/2310/TDS3301/Tutorials/Tutorial 2/' #set your google drive path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0DViKD3KgX6"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJGXD_vm81QR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izoXe2nv81QW"
   },
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kHWBfkvD81QX"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  drive_path\n",
    "except NameError:\n",
    "  drive_path = ''\n",
    "\n",
    "df = pd.read_csv(drive_path + \"BigMartSales/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gICwJlT-81QY"
   },
   "outputs": [],
   "source": [
    "# check dimensionality\n",
    "print(\"Number of rows:\", df.shape[0])\n",
    "print(\"Number of features/columns:\", df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qx1lnD-R81Qb"
   },
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHZgq6Mn81Qd"
   },
   "source": [
    "## Checking data types (attribute types)\n",
    "**It's important to check data types to make sure they are correct. Sometimes a numeric column can be treated as an object type because there are junk text mixed in the data...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ysbT3y6i81Qe"
   },
   "outputs": [],
   "source": [
    "df.dtypes # df.info() works too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_nfP_sM81Qh"
   },
   "source": [
    "**If that is the case, you can manually convert them to the proper data type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9kuVYfa981Qh"
   },
   "outputs": [],
   "source": [
    "# example\n",
    "df[\"Item_Weight\"] = pd.to_numeric(df[\"Item_Weight\"], errors=\"coerce\")\n",
    "df[\"Outlet_Establishment_Year\"] = pd.to_numeric(df[\"Outlet_Establishment_Year\"], errors=\"coerce\")\n",
    "df['Outlet_Establishment_Year'] = pd.to_numeric(df['Outlet_Establishment_Year'], downcast='float')\n",
    "# errors=\"coerce\" will make sure any non-numeric will be converted into NaN\n",
    "\n",
    "# If your data has datetime object, can use pd.to_datetime() to convert to proper type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WB0RZPBJ81Qi"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xt6Qs2f381Qj"
   },
   "source": [
    "# Missing data\n",
    "**To check if there is any missing data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XVOZQlNk81Qj"
   },
   "outputs": [],
   "source": [
    "# Change the .sum() to .mean()*100 if you prefer it in %\n",
    "# You can even plot it out if you want, might be useful if there are too many features.\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31vWpx5H81Qk"
   },
   "outputs": [],
   "source": [
    "len(df[df.isna().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m6vkKYAe81Ql"
   },
   "outputs": [],
   "source": [
    "# At this point, you can either drop all rows containing NA or impute them (https://scikit-learn.org/stable/modules/impute.html).\n",
    "# There are different types of missing data (Missing at random, missing completely at random ...etc)\n",
    "# Deal with NA accordingly\n",
    "\n",
    "#df = df.dropna() # to drop all na\n",
    "#df = df.fillna(df.median()) # fill NA with median of each feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CT1mxGYJ81Qm"
   },
   "source": [
    "# Removing duplicated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSJ1aNmQ81Qm"
   },
   "outputs": [],
   "source": [
    "print(\"Total duplicated rows: \", sum(df.duplicated()))\n",
    "\n",
    "# drop duplicates\n",
    "df = df.drop_duplicates() # or df = df[~df.duplicateed()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vy3TsIY881Qn"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJ4qtEVg81Qn"
   },
   "source": [
    "# Measuring Central Tendency (Mean, median, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1GvnZYLt81Qn"
   },
   "outputs": [],
   "source": [
    "# All in one except \"mode\", also including quartile range, standard deviation and min max.\n",
    "df.describe() # by default only returns numeric type columns, use the parameter include=\"all\" to include all dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9HsNhSMn81Qo"
   },
   "outputs": [],
   "source": [
    "# To get the mean, median and mode of a feature, you can use pandas .mean() .median() or .mode() function\n",
    "# Example:\n",
    "\n",
    "print(\"Mean: \", df[\"Item_Outlet_Sales\"].mean())\n",
    "print(\"Median: \", df[\"Item_Outlet_Sales\"].median())\n",
    "print(\"Mode: \", df[\"Item_Outlet_Sales\"].mode().tolist()) # mode might return more than 1 value, eg pd.Series([1,1,2,2,3,3]) returns 1,2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dRYUu5kn81Qp"
   },
   "outputs": [],
   "source": [
    "# These measures can also be useful in descriptive analytics, for instance\n",
    "\n",
    "# Get the mean/average sales in 2009 by item_type\n",
    "filtered = df[df[\"Outlet_Establishment_Year\"] == 2009]\n",
    "display(filtered.groupby([\"Item_Type\"]).agg({\"Item_Outlet_Sales\": \"mean\"}))\n",
    "\n",
    "# Mode can be used to extract the most frequent data\n",
    "# Or you can use df[col].value_counts() and the first item is the mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w1PiIAwY81Qp"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsJWbx2Q81Qq"
   },
   "source": [
    "# Visualizing distribution of data\n",
    "**Simple plots can be done fast using pandas .plot(), alternatively seaborn is also quite good**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bNbwm9Q81Qq"
   },
   "source": [
    "## Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Ki5o34s81Qq"
   },
   "outputs": [],
   "source": [
    "df[\"Item_Outlet_Sales\"].plot(kind=\"hist\", bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wp2gXv-J81Qr"
   },
   "source": [
    "## Histogram + density plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bgJhvYLM81Qr"
   },
   "outputs": [],
   "source": [
    "ax = df[\"Item_Outlet_Sales\"].plot(kind=\"hist\")\n",
    "df[\"Item_Outlet_Sales\"].plot(kind=\"kde\", ax=ax, secondary_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qTcY-oa81Qs"
   },
   "outputs": [],
   "source": [
    "# Same output but using seaborn\n",
    "sns.displot(df[\"Item_Outlet_Sales\"], bins=10, kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5MLaA-N81Qu"
   },
   "source": [
    "### We can quantify skewness by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "toNQhN2981Qv"
   },
   "outputs": [],
   "source": [
    "# We can quantify skewness by\n",
    "print(\"Skewness: \", df[\"Item_Outlet_Sales\"].skew())\n",
    "# This shows that this variable is highly skewed to the right (positive skewness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QiZ4EtHN81Qw"
   },
   "source": [
    "### Transformation to reduce skewness\n",
    "- Common transformations are log, square root, or cube root to reduce positive skewness\n",
    "- If it is negatively skewed, you can use log, cube root or square transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xhfb4Ggh81Qw"
   },
   "outputs": [],
   "source": [
    "sqrt_transform = np.sqrt(df[\"Item_Outlet_Sales\"])\n",
    "sns.displot(sqrt_transform, bins=10, kde=True)\n",
    "print(\"Skewness: \", sqrt_transform.skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kdkAU7381Qw"
   },
   "source": [
    "## Q-Q Plot / Normality test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-0yCUZC81Qx"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from scipy.stats import normaltest # https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.normaltest.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9i4vzEU281Qx"
   },
   "outputs": [],
   "source": [
    "test = np.random.normal(0,1, 1000) # generate random data\n",
    "\n",
    "sns.displot(test, kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UWQVOOJ81Qy"
   },
   "source": [
    "#### QQ plot to visualize normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtjdzG--81Q7"
   },
   "outputs": [],
   "source": [
    "_ = sm.qqplot(test, line='45')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69zdUwU381Q8"
   },
   "source": [
    "#### Alternatively, a normality test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJRPI4XS81Q9"
   },
   "outputs": [],
   "source": [
    "# normality test, it's more efficient to do a normality test rather than plot q-q plot for all features in your dataset, especially when your data has a lot features.\n",
    "k2, p = normaltest(test)\n",
    "alpha = 1e-3\n",
    "print(\"p = {:g}\".format(p)) # a big p value means it's close to normal\n",
    "\n",
    "if p < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xx3quSvN81Q-"
   },
   "source": [
    "## Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QF4AgW_u81Q-"
   },
   "outputs": [],
   "source": [
    "df[\"Item_Type\"].value_counts().plot(kind=\"bar\")\n",
    "# using groupby works too: df.groupby(\"Item_Type\").size().sort_values(ascending=False).plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ku3HBWqr81Q_"
   },
   "source": [
    "## Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXHqbJjD81Q_"
   },
   "outputs": [],
   "source": [
    "# Boxplot on a numeric feature\n",
    "df[[\"Item_Outlet_Sales\"]].plot(kind=\"box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNOloGwx81RA"
   },
   "outputs": [],
   "source": [
    "# box plot to show distributions with respect to categories\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11.7, 8.27))\n",
    "sns.boxplot(data=df, x='Outlet_Type', y='Item_Outlet_Sales', ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXxoRVwS81RB"
   },
   "source": [
    "## Correlation plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-c8G7fT81RB"
   },
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "sns.heatmap(corr, vmax=.8, square=True, annot=True, fmt= '.2f',\n",
    "            annot_kws={'size': 15}, cmap=sns.color_palette(\"Blues\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAgWXk3f81RC"
   },
   "source": [
    "## Scatterplot\n",
    "#### * We'll use iris dataset here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLZ4d45N81RC"
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwlQ1C-381RD"
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(data=iris[\"data\"], columns=iris[\"feature_names\"])\n",
    "df2[\"target\"] = [iris[\"target_names\"][i] for i in iris[\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lExRKvjQ81RD"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"sepal length (cm)\", y=\"petal length (cm)\", data=df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKE8c4P281RE"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"sepal length (cm)\", y=\"sepal width (cm)\", data=df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TaJFPZu81RF"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"petal length (cm)\", y=\"sepal width (cm)\", data=df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3GwiZCro81RF"
   },
   "outputs": [],
   "source": [
    "corr = df2.corr()\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "sns.heatmap(corr, vmax=.8, square=True, annot=True, fmt= '.2f', annot_kws={'size': 15}, cmap=sns.color_palette(\"Reds\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJySvgv281RG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "__8mlhin81RG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
