{"cells":[{"cell_type":"markdown","metadata":{"id":"lf7l2EXUdZMY"},"source":["# Lab06 - Textures\n","### TDS3651 Visual Information Processing\n"]},{"cell_type":"markdown","metadata":{"id":"fCJ53qsydZMb"},"source":["This lab will guide you on how to extract texture features. We first look at extracting simple textures from an image and how to find the cluster of different texture using K-Means.\n","\n","We will then explore the Leung-Malik (LM) Filter Bank code provided by the Visual Geometry Group, University of Oxford. We first learn how to create a set of 48-D filters with the LM Filter Bank. Following that, we learn how to apply the filters in the filter bank onto an input image to create a 48-D texture histogram to represent the textures of the image and use thee texture histogram for image retrieval."]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"fo7kaxdCevfH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = '/content/drive/MyDrive/Subjects/TDS3651/2210/Labs/Lab06/'"],"metadata":{"id":"sDOT3dhjevnH"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B2C7NvrRdZMc"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n"]},{"cell_type":"markdown","metadata":{"id":"KzOxivPwdZMd"},"source":["## Extract Simple Image Features\n","\n","The following program extract horizontal (dx) and vertical (dy) gradient features from an input image using the Sobel filter. The resulting Sobel detected gradients are thresholded to a binary image. Change the threshold value, `t` and observe how the threshold affects the plotted results.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y0bBubuIdZMd"},"outputs":[],"source":["img = cv2.imread(path+'brick2.jpg',0)\n","\n","# Output dtype = cv2.CV_8U\n","sobelx8u = cv2.Sobel(img,cv2.CV_8U,1,0,ksize=3)\n","sobely8u = cv2.Sobel(img,cv2.CV_8U,0,1,ksize=3)\n"," \n","t = 100\n","ret,textureFeatx = cv2.threshold(sobelx8u,t,255,cv2.THRESH_BINARY)\n","ret,textureFeaty = cv2.threshold(sobely8u,t,255,cv2.THRESH_BINARY)\n","textureFeatx[textureFeatx==255] = 1\n","textureFeaty[textureFeaty==255] = 1\n","\n","plt.figure(figsize=(20,20))\n","plt.subplot(1,3,1),plt.imshow(img,cmap = 'gray')\n","plt.title('Original'), plt.xticks([]), plt.yticks([])\n","plt.subplot(1,3,2),plt.imshow(textureFeatx,cmap = 'gray')\n","plt.title('Sobel X'), plt.xticks([]), plt.yticks([])\n","plt.subplot(1,3,3),plt.imshow(textureFeaty ,cmap = 'gray')\n","plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"X4iiCRXbdZMe"},"source":["Next, we divide the images into grids of size 32x32 and compute the sum of the dx and dy responses. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UDLe_dXjdZMf"},"outputs":[],"source":["winsz = 32; #window size to get texture\n","#calculate sliding window steps\n","rows=int(textureFeatx.shape[0]/winsz)\n","cols=int(textureFeaty.shape[1]/winsz)\n","i=j=k=0\n","N = rows*cols #number of texture windows\n","\n","#loop to sum up edges in window to form texture (can be mean or standard deviation)\n","dx=np.empty([N])\n","dy=np.empty([N])\n","for i in range(0, rows):\n","    for j in range(0, cols):\n","        dx[k] = sum(sum(textureFeatx[i*winsz:(i*winsz)+(winsz-1),j*winsz:(j*winsz)+(winsz-1)]))\n","        dy[k] = sum(sum(textureFeaty[i*winsz:(i*winsz)+(winsz-1),j*winsz:(j*winsz)+(winsz-1)]))\n","        k=k+1\n","\n","plt.figure(figsize=(10,7))\n","plt.scatter(dx, dy, s=10)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Nc_743O7dZMg"},"source":["**Perform K-Means clustering on the image grids** \n","\n","The following code uses the KMeans function from the sklearn package to find the texture-based clusters from the 2-D, dx and dy features. <br>\n","**Note**: Depending on your machine, this may take awhile to run."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JSxMK3vVdZMg"},"outputs":[],"source":["from matplotlib import style\n","style.use(\"ggplot\")\n","from sklearn.cluster import KMeans\n","\n","X1=np.zeros([dx.shape[0],2])\n","X1[:,0] = dx\n","X1[:,1] = dy\n","\n","n_clusters=4\n","kmeans = KMeans(n_clusters)\n","kmeans.fit(X1)\n","\n","centroids = kmeans.cluster_centers_\n","print(centroids)\n","labels = kmeans.labels_\n","\n","colors = [\"g.\",\"r.\",\"c.\",\"y.\"]\n","\n","plt.figure(figsize=(10,7))\n","for i in range(len(X1)):\n","    plt.plot(X1[i][0], X1[i][1], colors[labels[i]], markersize = 7)\n","\n","plt.scatter(centroids[:, 0],centroids[:, 1], marker = \"x\", s=150, linewidths = 5, zorder = 10)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ZE3xcCvsdZMh"},"source":["Alternatively, you can use the scipy version to support vector quantization. The cluster centers can be saved (as a codebook) to be re-used for clustering new data into the computed clusters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yd5meyr2dZMh"},"outputs":[],"source":["from matplotlib import style\n","from scipy.cluster.vq import kmeans, vq\n","\n","X2=np.zeros([dx.shape[0],2])\n","X2[:,0] = dx\n","X2[:,1] = dy\n","\n","n_clusters=4 \n","# k-means algo: data in MxN: M observations, N features \n","codebook, _ = kmeans(np.float32(X2), n_clusters)    \n","\n","# k by N codebook, showing k centroids of N-dimensions\n","print(codebook)\n","\n","# VQ assigns each observation to its \"code\", which is its cluster label\n","code, _ = vq(np.float32(X2), codebook)\n","print(np.max(code))  # k=4 means labels are 0, 1, 2, 3\n","print(code.shape)\n","\n","colors = [\"g.\",\"r.\",\"c.\",\"y.\"]\n","\n","plt.figure(figsize=(10,7))\n","for i in range(len(X2)):\n","    plt.plot(X2[i][0], X2[i][1], colors[code[i]], markersize = 7)\n","\n","plt.scatter(codebook[:, 0],codebook[:, 1], marker = \"x\", s=150, linewidths = 5, zorder = 10)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"4EFxRTQ0dZMi"},"source":["**Q1**: Create a visualization output to visualize the 4 clusters on the input image.\n","\n","[Hint: An example of a visualization of the texture clusters is illustrated in Slide 24 of Lecture 7: Textures]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KXkhBkWPdZMi"},"outputs":[],"source":["\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MTwiDzThdZMi"},"source":["## Filter Bank\n","\n","The Leung-Malik (LM) Filter Bank python implementation is provided in the lm.py file in the folder, 'LM_filter_bank'. The LM filter bank is a multi scale, multi orientation filter bank with 48 filters. It consists of first and second derivatives of Gaussians at 6 orientations and 3 scales making a total of 36; 8 Laplacian of Gaussian (LOG) filters; and 4 Gaussians.\n","\n","The code to create the LM filter bank and display the respective filters are given below. Run the code snipplets to understand more about the filters provided by the LM filter bank.\n","\n","Reference: http://www.robots.ox.ac.uk/~vgg/research/texclass/filters.html"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dpOnzhBpdZMj"},"outputs":[],"source":["#update the path to import from Drive\n","import sys\n","sys.path.append(path)\n","\n","# Import the LM filter bank\n","from LM_filter_bank import lm\n","\n","# Call the function to create a set of 48 filters\n","F = lm.makeLMfilters()\n"]},{"cell_type":"markdown","metadata":{"id":"SzVDFMKvdZMj"},"source":["## First order derivative Gaussian Filter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zrXzun-odZMj"},"outputs":[],"source":["for i in range(0,18):\n","    plt.subplot(3,6,i+1)\n","    plt.axis('off')\n","    plt.imshow(F[:,:,i], cmap = 'gray')"]},{"cell_type":"markdown","metadata":{"id":"iIzoGWvUdZMj"},"source":["## Second order derivative Gaussian Filter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9jOqYWDVdZMk"},"outputs":[],"source":["for i in range(0,18):\n","    plt.subplot(3,6,i+1)\n","    plt.axis('off')\n","    plt.imshow(F[:,:,i+18], cmap = 'gray')"]},{"cell_type":"markdown","metadata":{"id":"9s26w4I6dZMk"},"source":["## Gaussian and Laplacian Filter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D4AqVazfdZMk"},"outputs":[],"source":["for i in range(0,12):\n","    plt.subplot(4,4,i+1)\n","    plt.axis('off')\n","    plt.imshow(F[:,:,i+36], cmap = 'gray')"]},{"cell_type":"markdown","metadata":{"id":"ODa1fW_pdZMk"},"source":["The LM Filter Bank provide 48 filters as illustrated above. The following code snipplet applies selected filters from the filter bank to an image. Run the program and then change the filter index to explore the results of different filters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rQvp2hAfdZMk"},"outputs":[],"source":["img = cv2.imread(path+'carpet.jpg',0);\n","\n","filterImg1 = cv2.filter2D(img,-1,F[:,:,0])    \n","filterImg2 = cv2.filter2D(img,-1,F[:,:,8])    \n","filterImg3 = cv2.filter2D(img,-1,F[:,:,30])    \n","filterImg4 = cv2.filter2D(img,-1,F[:,:,40])\n","filterImg5 = cv2.filter2D(img,-1,F[:,:,46])    \n","\n","plt.figure(figsize=(20,20))\n","plt.subplot(1,5,1), plt.imshow(filterImg1, cmap='gray'),  plt.xticks([]), plt.yticks([])\n","plt.subplot(1,5,2), plt.imshow(filterImg2, cmap='gray'),  plt.xticks([]), plt.yticks([])\n","plt.subplot(1,5,3), plt.imshow(filterImg3, cmap='gray'),  plt.xticks([]), plt.yticks([])\n","plt.subplot(1,5,4), plt.imshow(filterImg4, cmap='gray'),  plt.xticks([]), plt.yticks([])\n","plt.subplot(1,5,5), plt.imshow(filterImg5, cmap='gray'),  plt.xticks([]), plt.yticks([])\n","plt.show()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"DbAsMV0edZMl"},"source":["**Q2**: **Write a function to return a texture histogram of a given image** \n","\n","Given an input image as the parameter, complete the textureHist function below that returns a texture historgram that consists of 48-D response obtained by applying the 48 filters of the Leong-Malik filter bank on the input image.\n","\n","Hint: To support comparison of histogram features, normalize the histogram by the image size, ensure the clusters are the same every time."]},{"cell_type":"code","source":["def textureHist(img):\n"," \n","  #enter code here\n","  \n","  return textHist\n","\n","img1_hist = textureHist(img)\n","plt.bar(np.arange(48),img1_hist)\n","plt.show()"],"metadata":{"id":"Gr4Mfz7jD7d3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kx9bJ_7KdZMl"},"source":["**Q3**: **Compute similarity between images by comparing the texture histograms for image retrieval** \n","\n","Write a program to compute the texture similarity between the image, brickwall1.jpg with the following images <br>\n","    a) brickwall2.jpg <br>\n","    b) carpet.jpg <br>\n","    c) waterdrop.jpg\n","\n","Make use of the above defined function, textureHist. Use either Euclidean distance or histogram intersection to compute the distance between the 48-D texture histograms of the respective images. Display the tetxure historgram of the each image, along with the distances between the image, brickwall1.jpg and the other 3 images.\n","\n","Are the results accurate? Analyse the results and record your observation.\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"fTDHXI1PCRnU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OE33A0XgD-Is"},"execution_count":null,"outputs":[]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}