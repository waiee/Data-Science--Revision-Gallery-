{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kkk0P3IB0KVi"
   },
   "source": [
    "# Lab01 - Getting Started\n",
    "### TDS3651 Visual Information Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l83uj4ni0KVr"
   },
   "source": [
    "### Have you gone through Lab 00?\n",
    "\n",
    "Lab 00 serves as a quick refresher to Python language (at least sufficient for you to code when you get into the main topics of this course). If you have not done it, please make sure you go through it during your Self-Learning Time. \n",
    "\n",
    "### This lab\n",
    "\n",
    "**TDS3651 Visual Information Processing** labs are primarily guided and self-paced, while it also contains some questions that you are require to complete and additional exercises (usually at the end). The instructor will not provide any solutions, so as to encourage you to discuss this with other students.\n",
    "\n",
    "This lab introduces some basic input/output mechanisms for handling images, and some fundamental image processing operations such as arithmetic operations, and image blending. This lab is primarily guided (in many portions) while it also contains sections that you are require to complete. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lfm9uwf0KVt"
   },
   "source": [
    "## Image Libraries for Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-E2wFUp0KVu"
   },
   "source": [
    "Among the more popularly used libraries for processing images and videos in the Python environment are: \n",
    "* [**OpenCV**](https://docs.opencv.org/trunk/index.html) \n",
    "* [**Pillow**](https://pillow.readthedocs.io/en/latest/index.html) (previously known as **Python Imaging Library (PIL)**).\n",
    "* [**scikit-image**](http://scikit-image.org/docs/stable/), which is the image processing library of SciPy.\n",
    "\n",
    "We will be mainly using the OpenCV library in most practical modules (as it is the richer of the two in terms of functionalities for image processing and computer vision), although some exposure to PIL is also helpful and might come in handy at times. OpenCV itself has slightly different functionality sets for C++ and Python languages, with the C++ library being the more complete of the two. The scikit-image is not as widely used but it contains some useful implementations. \n",
    "\n",
    "OpenCV also comes with a very comprehensive bunch of Python tutorials which you can find [here](https://docs.opencv.org/trunk/d6/d00/tutorial_py_root.html). Due to some syntax differences between the C++ and Python versions, you can use the function `help(function-name)` and the C++ OpenCV reference to cross-check the usages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJPHrBLM0KVv"
   },
   "source": [
    "### Before starting\n",
    "#### [For those using own PC/laptops]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5b_73gs0KVv"
   },
   "source": [
    "First, ensure that you have got the latest OpenCV version (4.5.3) installed for Python. There are many ways (and many packaged versions) that can get you OpenCV installed. \n",
    "\n",
    "#### OpenCV\n",
    "Following the instructions provided, type at terminal/prompt: \n",
    "\n",
    "`pip install opencv-python`. \n",
    "\n",
    "If you have an existing OpenCV packages installed and you wish to upgrade it. You can type at terminal/prompt: \n",
    "\n",
    "`pip install --upgrade opencv-python`\n",
    "\n",
    "Some dependencies might be updated along the process.   \n",
    "\n",
    "#### Pillow & scikit-image\n",
    "Both Pillow and scikit-image packages come together with Anaconda. However, their existing versions may be slightly outdated. You can update them together using conda:\n",
    "\n",
    "`conda update pillow scikit-image`\n",
    "\n",
    "Some dependencies might be updated along the process.   \n",
    "\n",
    "After getting these packages installed, let's check if they have been properly installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VS3XiDh50KVx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OEgtaV730KVz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.0.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image \n",
    "Image.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-uVtr1G00KV1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\waiee\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.19.2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import skimage\n",
    "skimage.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icq4peMu1dui"
   },
   "source": [
    "#### [For Google Colab users]\n",
    "\n",
    "Mount your Google Drive to this session and set the path of the specific folder you kept the materials of this lab in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pYHtwcyE2EB9"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8yu2S4D2g7J"
   },
   "source": [
    "Set the path of the active folder of this lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-ukvQuEZ1_Ki"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (1980956617.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [10]\u001b[1;36m\u001b[0m\n\u001b[1;33m    path = 'C:\\Users\\waiee\\Downloads\\Final Year Sem 1\\VIP\\tuto01\\Lab01 Images'\u001b[0m\n\u001b[1;37m                                                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "path = 'C:\\Users\\waiee\\Downloads\\Final Year Sem 1\\VIP\\tuto01\\Lab01 Images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ho-S1q7L0KV2"
   },
   "source": [
    "Also, make sure some of the other supporting libraries are also available in your Python environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MC7MjfWB0KV3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfuqP5Q00KV4"
   },
   "source": [
    "If all is good, let's get started with some image reading and writing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPswqVkw0KV4"
   },
   "source": [
    "## Image Reading, Displaying, Writing\n",
    "\n",
    "The first steps to have an image loaded to the memory of your computer is to read it from an image file. Doing it on Python is as simple as a one-liner. Of course, there are other sophisticated ways of reading an image from a URL or through the network, but we will not be covering those techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8IDOlaRX0KV5"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[43mpath\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopencv-logo.png\u001b[39m\u001b[38;5;124m'\u001b[39m)                              \u001b[38;5;66;03m# IMREAD always reads an RGB image in B-G-R order (reversed)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m img_gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopencv-logo.png\u001b[39m\u001b[38;5;124m'\u001b[39m,cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)    \u001b[38;5;66;03m# read image directly as grayscale\u001b[39;00m\n\u001b[0;32m      4\u001b[0m img_gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopencv-logo.png\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(path + 'opencv-logo.png')                              # IMREAD always reads an RGB image in B-G-R order (reversed)\n",
    "img_gray = cv2.imread(path + 'opencv-logo.png',cv2.IMREAD_GRAYSCALE)    # read image directly as grayscale\n",
    "\n",
    "img_gray = cv2.imread(path + 'opencv-logo.png',0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3Uvv2xU0KV5"
   },
   "source": [
    "Note: OpenCV uses the \"BGR\" arrangement instead of more conventional understanding of \"RGB\". (For the long story, you can read [here](https://www.learnopencv.com/why-does-opencv-use-bgr-color-format/) why is it so).\n",
    "\n",
    "We can then verify if the two images are correctly read by checking its dimension from the variable list,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2-jBHd8c0KV6"
   },
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzvRjBJk0KV6"
   },
   "source": [
    "Noticed also that the size that the image occupies in your computer's memory is given in bytes (and in kb, Mb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2z105jBZ0KV9"
   },
   "source": [
    "### Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OjELIzx0KV-"
   },
   "source": [
    "Next, we can display the image within the notebook.<br>\n",
    "Matplotlib is a plotting library for Python which gives you wide variety of plotting methods. Here, you will learn how to display image with Matplotlib. With Matplotlib, you can also display interactive plots which can zoom in and out of images, save and etc, using the additional line `%matplotlib %notebook`. If you are using Jupyter, all plots are plotted inline (in the notebook) by default.\n",
    "\n",
    "For ease of plotting correctly with matplotlib, it is good to have it converted to RGB ordering (instead of BGR from OpenCV). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N--Dyv0i0KV-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)      # is a good idea to convert BGR to RGB as matplotlib uses RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hBdtTXqi0KV_",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# the 'notebook' option enables interactive plots. Note: switch back to the 'inline' option later on. \n",
    "\n",
    "#%matplotlib notebook   \n",
    "import matplotlib  # temporary hack\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3bHlOzIVsCn9"
   },
   "outputs": [],
   "source": [
    "plt.imshow(img_gray,cmap='gray')\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hcFIdxe0KV_"
   },
   "source": [
    "Have a look at more plotting styles and features from [this documentation](http://matplotlib.org/api/pyplot_api.html). Try out some if you wish.\n",
    "\n",
    "If you are using Jupyter Notebook on your own machine, you can also try using the functions from OpenCV to display the images.<br> \n",
    "The function will open a new window to show the image.<br>\n",
    "Note: OpenCV `imshow()` function is restricted on Google Colab as it will crash your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xo9_4gJ0KV7"
   },
   "outputs": [],
   "source": [
    "cv2.imshow('Color image',img)\n",
    "cv2.imshow('Grayscale image',img_gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()      # this snippet of code will finish execution when the two windows are closed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJ5MM4N40KV7"
   },
   "source": [
    "And also by displaying them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ey9HjlFr0KV8"
   },
   "outputs": [],
   "source": [
    "cv2.imshow('Color image',img)\n",
    "cv2.imshow('Grayscale image',img_gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()      # this snippet of code will finish execution when the two windows are closed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVD3Gdoo0KV9"
   },
   "source": [
    "The last two lines of code are handling the display of the image in an external (pop-out) window. The last line particularly waits for you to close \n",
    "\n",
    "Now, let's save the grayscale image as a file to disk. After that, check if you can find the newly saved image file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8uxMcWa0KV9"
   },
   "outputs": [],
   "source": [
    "cv2.imwrite(path + 'opencv-gray.png',img_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvnfJxh30KV_"
   },
   "source": [
    "### Basic Operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRFSvEit0KWA"
   },
   "source": [
    "Next, let's look at some basic image operations that will come in handy later.\n",
    "\n",
    "You can access a pixel value by its row and column coordinates. Since we have already converted the BGR image to a standard RGB image, it returns an array of Red, Green, Blue values (in this order), respectively. For grayscale image, it is straightforward; the corresponding intensity is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M9psaB250KWA"
   },
   "outputs": [],
   "source": [
    "# accessing a location at the blue region of the logo\n",
    "px = img[500, 400]\n",
    "print(px)\n",
    "\n",
    "# accessing only the blue pixel at that same location\n",
    "blue = img[500,400,2]\n",
    "print(blue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6qwNA-AC0KWA"
   },
   "source": [
    "These pixel intensity values can be modified by assigning a new colour to it. Let's modify that same pixel to white colour, and then, try changing more pixels at one go (using numpy slicing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FAz3VdLN0KWB"
   },
   "outputs": [],
   "source": [
    "# Change pixel colour to white\n",
    "img[500, 400] = [255, 255, 255]\n",
    "plt.imshow(img)\n",
    "plt.xticks([]), plt.yticks([])  \n",
    "plt.show()      # can you see the white dot? :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pb685Uxu0KWB"
   },
   "outputs": [],
   "source": [
    "# Change a larger patch of pixels (20x20 in size), all to white\n",
    "patchsize = 20\n",
    "img[500:500+patchsize, 400:400+patchsize] = [255, 105, 15]\n",
    "plt.imshow(img)\n",
    "plt.xticks([]), plt.yticks([])  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWRHQolc0KWB"
   },
   "source": [
    "Let's check the value of a pixel in that patch area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCD-tomF0KWC"
   },
   "outputs": [],
   "source": [
    "\n",
    "img[510, 415]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJTfbkNh0KWC"
   },
   "source": [
    "There are other Numpy methods that are help to find image properties. \n",
    "\n",
    "The \"shape\" of image is accessed by img.shape *(I personally prefer to call it 'size' of the image, but perhaps they want to be generic when identifying n-dimensional arrays.)* `img.shape` returns a tuple of number of rows, columns and channels (if image is color). Image datatype is obtained by `img.dtype` while the total number of pixels can be accessed by `img.size` \n",
    "\n",
    "What is the actual size of the data (in bytes) that's residing in the memory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-nW1K75M0KWC"
   },
   "outputs": [],
   "source": [
    "print(img.shape)\n",
    "print(img.size)\n",
    "print(img.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKCXDodT0KWD"
   },
   "source": [
    "Note: `img.dtype` is very important while debugging because a large number of errors in OpenCV-Python code is caused by invalid datatype.\n",
    "\n",
    "Of course, it's easy to just use `whos` to display all these properties (but all variables in memory are shown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yERnjt7G0KWD"
   },
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkBdKopt0KWD"
   },
   "source": [
    "Before we proceed further, let's put the image displaying codes into a function definition, so that we can just call it with a single function call from hereon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-1y_ufC0KWE"
   },
   "outputs": [],
   "source": [
    "def showImage(img, titlestr=\"\" ):\n",
    "    if img.ndim == 2:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(img)\n",
    "    plt.xticks([]), plt.yticks([])  \n",
    "    plt.title(titlestr)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5UXP15h0KWE"
   },
   "source": [
    "**Q1.** Call the function `showImage` to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wilZWzE_0KWE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obrnqTOq0KWE"
   },
   "source": [
    "### Image ROI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLTWL_Ur0KWF"
   },
   "source": [
    "A Region-of-Interest (ROI) refers to a certain sub-part or region of the image that you wish to process. Let's try to cut a ROI from the logo image and swap it with another ROI within the image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9KDZRR-0KWF"
   },
   "outputs": [],
   "source": [
    "# redROI = img[272:600, 315:600]               # this slicing merely takes a 'view' into the same data, no copies made\n",
    "redROI = img[272:600, 315:600].copy()          # enables deep copy --> make another copy elsewhere in memory\n",
    "img[272:600, 315:600] = img[272:600, 0:285];\n",
    "img[272:600, 0:285] = redROI \n",
    "showImage(img)\n",
    "\n",
    "# Note: running this cell another time will swap back the blue and green 'C's !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7afGp9pC0KWF"
   },
   "source": [
    "### Splitting/Merging Image Channels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y54-AWLj0KWF"
   },
   "source": [
    "If you need to work separately on the individual R, G, or B channels of a color image, then you need to split the RGB images to single planes. You can also join these individual channels back to a RGB image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQRP5Buv0KWG"
   },
   "outputs": [],
   "source": [
    "r,g,b = cv2.split(img)              \n",
    "img = cv2.merge((r,g,b))\n",
    "showImage(img)     # verify that image is still the same after joining back\n",
    "\n",
    "# Another function for setting subplot images --> Note: plt.show() only called after all subplots defined\n",
    "def showSubplotImage(img, titlestr=\"\" ):\n",
    "    plt.imshow(img, cmap = 'gray', interpolation = 'bicubic')\n",
    "    plt.xticks([]), plt.yticks([])  \n",
    "    plt.title(titlestr)\n",
    "\n",
    "# Creating 3 subplots (in 1 row) to show the 3 planes for each colour channel\n",
    "fig = plt.subplots(nrows=1, ncols=3)\n",
    "plt.subplot(131), showSubplotImage(r, 'Red plane')\n",
    "plt.subplot(132), showSubplotImage(g, 'Green plane')\n",
    "plt.subplot(133), showSubplotImage(b, 'Blue plane')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXGFvOk20KWH"
   },
   "source": [
    "More on colors later on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xgKnh_h0KWH"
   },
   "source": [
    "## Arithmetic Operations on Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_0AcgBN0KWI"
   },
   "source": [
    "Image addition in OpenCV is pretty easy. Intuitively, the `+` sign should suffice in performing this operation. Let's try adding two images together..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-fh5-eL70KWI"
   },
   "outputs": [],
   "source": [
    "img_ml = cv2.imread(path + 'ml.png')\n",
    "added = img_gray + img_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNKjZkKa0KWI"
   },
   "source": [
    "This is not possible because you cannot add two arrays that are of different dimensions! So let's resize one of the two images to follow the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQwgur5C0KWI"
   },
   "outputs": [],
   "source": [
    "dim = (344, 397)\n",
    "opencv_resized = cv2.resize(img, dim)\n",
    "opencv_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YwItD5xn0KWJ"
   },
   "outputs": [],
   "source": [
    "added = opencv_resized + img_ml\n",
    "showImage(opencv_resized, 'OpenCV')\n",
    "showImage(img_ml, 'ML')\n",
    "showImage(added, 'OpenCV + ML')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7erm8w90KWJ"
   },
   "source": [
    "Something not quite right still! The added image does not seemed to be correctly blended. This is because Numpy addition `+` can easily result in an overflow of the `uint8` range. Try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_h_DvNB40KWK"
   },
   "outputs": [],
   "source": [
    "x = np.uint8([250])\n",
    "y = np.uint8([255])\n",
    "print(x - y)    # this is 250 + 10 = 260 , when it overflows past 255, the added values start over again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3yYhoTOh0KWK"
   },
   "outputs": [],
   "source": [
    "added2 = cv2.add(img_ml, opencv_resized)\n",
    "showImage(added2, 'OpenCV + ML image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8dt0BmF0KWK"
   },
   "source": [
    "To have more control over how much each of the two images can be blended together, try the function `cv2.addWeighted`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "flVrEF370KWL"
   },
   "outputs": [],
   "source": [
    "blended = cv2.addWeighted(img_ml,0.7,opencv_resized,0.3,0)     # 70% of ML image, 30% of OpenCV image\n",
    "showImage(blended, 'Blended 70%-30%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgXLD-Js0KWL"
   },
   "source": [
    "**Q2**. Create a GIF animation by creating a series of images that capture a  smooth transition between two blended images. You may use the image blending operation done earlier with the weighted addition function `cv2.addWeighted`.\n",
    "\n",
    "The `imageio` package (available in Anaconda) has this nifty feature that allows us to save a list of images into a GIF file. Some of these utility code are given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i9VTG90G0KWL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import imageio\n",
    "\n",
    "# folder containing the images needed\n",
    "gif_dir = path + \"gif_folder/\"\n",
    "\n",
    "# creates the folder if it does not exist\n",
    "if not os.path.exists(gif_dir):  \n",
    "    os.makedirs(gif_dir)\n",
    "\n",
    "# add your code here in a loop ####################\n",
    "for i in range(11):\n",
    "    # add code\n",
    "    \n",
    "    \n",
    "    \n",
    "# to generate the GIF from a series of images in a folder\n",
    "images = []\n",
    "for subdir, dirs, files in os.walk(gif_dir):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(subdir, file)\n",
    "        if file_path.endswith(\".png\"):\n",
    "            images.append(imageio.imread(file_path))\n",
    "imageio.mimsave(path+'/movie.gif', images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5Ikaui10KWM"
   },
   "source": [
    "How about subtracting two images? Are there any negative values after doing this?\n",
    "\n",
    "What if we find the absolute difference between two images instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rq1eGDzz0KWM"
   },
   "outputs": [],
   "source": [
    "subtracted = cv2.subtract(img_ml, opencv_resized)       # which subtracted which?\n",
    "showImage (subtracted, 'Which subtracted which?')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pXZYNb200KWM"
   },
   "outputs": [],
   "source": [
    "absdifferenced = cv2.absdiff(img_ml, opencv_resized)\n",
    "showImage (absdifferenced, 'Abs Diff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ql25Nrak0KWN"
   },
   "source": [
    "## Using Spyder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckUuPIWC0KWN"
   },
   "source": [
    "Ultimately, some people may find using Jupyter notebooks a hassle when they need to re-run big portions of code (including some earlier code as well), but of course some may not if they know how to utilize nifty options from the \"Cell\" menu item. If you do, you can try using Spyder, which is a typical IDE that gives you better control in writing programs.\n",
    "\n",
    "**Q3.** Just to be familiar, transfer some code (eg. the animated gif program) from this lab tutorial to Spyder (create new .py file, run), and get it working. Writing codes over there gives you a better view of what code can be further modularized into functions. If you ever need to test out short snippets of code over there, the iPython console is visible there as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3wzxjNMJi8tk"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NT9O3Kpi0KWN"
   },
   "source": [
    "## Trying Pillow & scikit-image packages\n",
    "\n",
    "Our practicals will be mostly focused on the OpenCV library. Feel free to try out some hands-on tutorial on the other two libraries: [Pillow](https://pillow.readthedocs.io/en/latest/handbook/tutorial.html) and [`scikit-image`](http://www.scipy-lectures.org/packages/scikit-image/index.html#introduction-and-concepts).\n",
    "\n",
    "Most of these basic operations covered in this module are available on all three libraries. Perhaps the comprehensiveness of the OpenCV library would be most telling in the advanced topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSnJxvK30KWN"
   },
   "source": [
    "## Additional Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PL8Wp6840KWO"
   },
   "source": [
    "**Q**. Write a handy function that can show multiple images in a single figure using the `subplot` function, given the number of images. Decide what other parameters may be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IndVgkJN0KWO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
